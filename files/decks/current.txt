What does an imputer do?

- It is an Imputation transformer for completing missing values

What are some actions you need to do for Data Cleaning?
1. The ML algorithms wont work with missing features, so you have to take care of them, for example with an imputer
2. You can also get rid of the whole attribute of the missing features

The important objects of Scikit-Learns API?
- Estimators
- Transformers
- Predictors

Why do you have to write your own custom Transformers?
- Because I need custom cleanup operation
- Or have to combine specific attributes

What do you have to do to create your own Transformers, when It have to work seamlessly with Scikit-Learn functionalities?
- Creating a class and implement three methods:
    1. fit() - returning self
    2. transform()
    3. fit_transform()

What is the most important transformations you need to apply to your data and why?
- Feature Scaling, because Ml algorithms dont perform well when the input
numerical attributes have very different scales

What can you do to get all attributes to have the same scale?
- min-max scaling (normalization)
- standardization

How to execute all the data transformations in the right order?
- One good possibility is to use the Scikit-learn Pipeline class, that helps
with such sequences

What is Machine Learning?
- A computer program is said to learn from experience E with respect to some task T
and some performance measure P, if its performance on T, as measured by P,
improves with experience E.
- Actually you give a machine or algorithm input to learn and improve by itself

What is the Machine Learning Process or approach?
1. Data
2. Train ML Algorithm
3. Evaluate Solution
4. Launch
5. Update Data
6. Train ML Algorithm and again

What is data mining and explain the process behind it?
- Data mining is basically the discovery of patterns in large amount of data with ML techniques

What is Machine Learning great for?
- Problems for which existing solutions require a lot of fine-tuning or long lists of rules
- Complex problems fr which using a traditional approach yields no good solution
- Fluctuating environments
- Getting insights about complex problems and large amounts of data

What are the main challenges of Machine Learning?
- Insufficient Quantity of Training Data
- Nonrepresentative Training Data
- Poor-Quality Data
- Irrelevant Features
- Over- and Underfitting the Training Data
- Hypterparameter Tuning and Model Selection
- Data Mismatching

Why is Hyperparameter Tuning useful for Model Selection?
- For finding the best hyperparameters for a model that also performs well on new data and not only on a particular set
- A common solution is therefore holdout validation, you simply hold out part of the training set to evaluate several candidate models and select the best one
- If the validation set is too small or large you can use cross-validation on many small validation sets.

What is a labeled training set?
- A labeled training set is a training set that contains the desired solution (a.k.a. a label) for each instance.

What are the two most common supervised tasks?
- Regression and classification

What are four common unsupervised tasks?
- Common unsupervised tasks include clustering, visualization, dimensionality reduction, and association rule learning.

What type of algorithm would you use to segment your customers into multiple groups?
- If you don’t know how to define the groups, then you can use a clustering algorithm (unsupervised learning) to segment your customers into clusters of similar customers. However, if you know what groups you would like to have, then you can feed many examples of each group to a classification algorithm (supervised learning), and it will classify all your customers into these groups.

What type of learning algorithm relies on a similarity measure to make predictions?
- An instance-based learning system learns the training data by heart; then, when given a new instance, it uses a similarity measure to find the most similar learned instances and uses them to make predictions.

What is the difference between a model parameter and a learning algorithm’s hyperparameter?
- A model has one or more model parameters that determine what it will predict given a new instance (e.g., the slope of a linear model). A learning algorithm tries to find optimal values for these parameters such that the model generalizes well to new instances. A hyperparameter is a parameter of the learning algorithm itself, not of the model (e.g., the amount of regularization to apply).

What do model-based learning algorithms search for, What is the most common strategy they use to succeed? How do they make predictions?
- Model-based learning algorithms search for an optimal value for the model parameters such that the model will generalize well to new instances.
- Minimizing the cost function

If your model performs great on the training data but generalizes poorly to new instances, what is happening, name three possible solutions?
- The model is likely overfitting the training data
1. Getting more data
2. Simplifying the model (selecting a simpler algorithm, reducing the number of parameters of features)
3. Reducing the noise in the training data

What is a test set ? 
- A test set is used to estimate the generalization error that a model will make on new instances, before the model is launched in production.

What is the purpose of a validation set?
- A validation set is used to compare models. It makes it possible to select the best model and tune the hyperparameters.

What is te train-dev set, when do you need it, and how do you use it?
- The train-dev set is used when there is a risk of mismatch between the training data and the data used in the validation and test datasets

What can go wrong if you tune hyperparameters using the test set?
- If you tune hyperparameters using the test set, you risk overfitting the test set, and the generalization error you measure will be optimistic


